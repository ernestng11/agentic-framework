llm_providers:
  openai:
    # API key automatically loaded from OPENAI_API_KEY environment variable
    default_model: "gpt-4o"
    default_temperature: 0.7
    fallback_models: ["gpt-4o-mini", "gpt-4o"]
  
  anthropic:
    # API key automatically loaded from ANTHROPIC_API_KEY environment variable
    default_model: "claude-3-sonnet-20240229"
    default_temperature: 0.7
    fallback_models: ["claude-3-haiku-20240307", "claude-3-opus-20240229"]

mcp_servers:
  - name: "file-system"
    transport: "stdio"
    command: "python"
    args: ["mcp_servers/filesystem_server.py"]
  
  - name: "database"
    transport: "http"
    url: "http://localhost:8080/mcp"

a2a_config:
  agent_registry_url: "http://localhost:9000/registry"
  authentication:
    type: "api_key"
    key: ${A2A_API_KEY}

agents:
  research:
    llm_provider: "openai"
    preferred_models: ["gpt-4o", "gpt-4o-mini"]
    capabilities: ["web_search", "data_analysis"]
    tools: ["web_search", "pdf_reader", "database_query"]
  
  planning:
    llm_provider: "anthropic"
    preferred_models: ["claude-3-sonnet-20240229", "claude-3-haiku-20240307"]
    capabilities: ["task_decomposition", "workflow_planning"]
    tools: ["calendar", "project_management"]

# System Configuration
system:
  port: 8000
  host: "localhost"
  debug: false
  log_level: "INFO"
  
  # Provider validation on startup
  validate_providers: true
  require_all_providers: false  # Set to true if all providers must be available

# Tool Configuration
tools:
  web_search:
    max_results: 10
    timeout: 30
  
  database:
    connection_timeout: 5
    query_timeout: 30
  
  file_reader:
    max_file_size: "10MB"
    supported_types: ["pdf", "txt", "json", "csv"]

# Security Configuration
security:
  rate_limiting:
    enabled: true
    requests_per_minute: 60
  
  api_keys:
    required: true
    validation: true
    
  # Provider-specific security settings
  provider_security:
    openai:
      timeout: 30
      max_retries: 3
    anthropic:
      timeout: 30
      max_retries: 3 